
# ğŸ¯ Feedback Authenticity: Distinguishing Genuine from Fake Reviews + Sentiment Analysis

## ğŸ“„ Project Description
An advanced Review Analyzer that detects both the authenticity and sentiment of user feedback.
It offers interactive dashboards, dynamic visualizations, and real-time insights.

## ğŸ› ï¸ Built with
- **Frontend**: React.js, Next.js
- **Backend**: Node.js, Express
- **Machine Learning Models**: PyTorch (DeBERTa, MBO, Unsloth, LoRA)

## ğŸ§  Genuinity Detection
Fine-tuned DeBERTa model + Monarch Butterfly Optimization (MBO).

## ğŸ—£ï¸ Sentiment Analysis
Standard DeBERTa model.

## ğŸ¤– Synthetic Data
Generated using LLaMA 70B.

## ğŸš€ API Deployment
Powered by Gradio.

## âœ¨ Features
- ğŸ” **Genuine Review Detection**: Classify reviews as authentic or fake using a fine-tuned DeBERTa model.
- â¤ï¸ **Sentiment Analysis**: Predict feedback sentiment: Positive, Negative, or Neutral.
- ğŸ“Š **Interactive Dashboards**: Clean visualization of results using lucide-react components.
- ğŸ’» **Modern Web Application**: Built with React.js, Next.js, Node.js, and Express.

## ğŸ› ï¸ Advanced Model Training
- DeBERTa fine-tuned with MBO for genuinity.
- Standard DeBERTa for sentiment classification.
- Unsloth and LoRA for efficient fine-tuning.

## ğŸ§ª Synthetic Data Generation
Large-scale data generation with LLaMA 70B.

## ğŸŒ API Deployment
Live model inference APIs with Gradio.

## ğŸ—ï¸ Project Architecture

![image](https://github.com/user-attachments/assets/ac7fddbc-c08c-41d3-9c01-20496bc9b470)



## ğŸš€ Tech Stack

| Category                | Technology/Tool                          | Purpose                                  |
|--------------------------|------------------------------------------|------------------------------------------|
| Frontend                 | React.js, Next.js, lucide-react          | Web application UI and visualization    |
| Backend                  | Node.js, Express, FastAPI                | Server-side logic                       |
| Database                 | MongoDB                                  | Data storage and management             |
| Model Training Framework | PyTorch                                  | Building and training ML models         |
| LLM Fine-tuning          | Unsloth, LoRA                            | Efficient LLM fine-tuning               |
| Sentiment Analysis Model | DeBERTa                                  | Sentiment classification                |
| Genuinity Detection Model| DeBERTa + Monarch Butterfly Optimization | Authenticity detection                  |
| Data Generation          | LLaMA 70B                                | Synthetic data generation               |
| API Deployment           | Gradio                                   | Model inference hosting                 |

## ğŸ“‚ Project Structure
```
/review-analysis     â†’ React frontend for submission, history, visualization
/backend              â†’ Node.js API server (routes, models, database)
/pythonBackend        â†’ Python backend for ML models and Gradio APIs
```

## ğŸ¨ Frontend (review-analysis)
- ğŸ“ Feedback Dashboard: Submit new feedback.
- ğŸ“š Feedback History: View previous feedbacks.
- ğŸ“Š Visualization Reports: Graphical representation of analysis.
- ğŸ› ï¸ Submits feedback to the Python backend for analysis.

## ğŸ› ï¸ Backend (backend)
- ğŸ“¡ API Endpoints: CRUD operations for feedback.
- ğŸ¤– Integrates sentiment & fake review detection models.
- ğŸ›¢ï¸ Saves analyzed data to MongoDB.

## ğŸ§  Models Used
- **mbo_deberta** â†’ Fake review detection
- **deberta** â†’ Sentiment analysis

## ğŸ§ª Python Backend (pythonBackend)
- **main.py**: Manages feedback processing and model interaction.
- **gradio_api_server.py**: Starts a live Gradio server.
- **requirements.txt**: Lists Python dependencies.

âš ï¸ **Important**:
- Run `gradio_api_server.py` manually to get a live Gradio link.
- Update the Gradio link inside `main.py` manually each time.

## ğŸ”„ Workflow Summary
1. ğŸ–Šï¸ User submits feedback via frontend.
2. ğŸ”— Frontend sends it to Python Backend (`main.py`).
3. ğŸ§  Python backend analyzes feedback using ML models.
4. ğŸ—„ï¸ Node.js backend saves the analysis in MongoDB.
5. ğŸ“Š User can view results and visualizations.

## ğŸ› ï¸ Execution Commands

**Frontend**
```bash
cd review-analysis
npm install
npm run dev
```

**Backend**
```bash
cd backend
npm install
npm start
```

**Python Backend**
```bash
cd pythonBackend
pip install -r requirements.txt
uvicorn main:app --host 0.0.0.0 --port 8000
```

**Start Gradio Server**
```bash
python gradio_api_server.py
```
(Remember to update the Gradio URL manually in `main.py`!)

## ğŸ–¼ï¸ UI Pages Overview
- ğŸ“ Feedback Dashboard
- 
![image](https://github.com/user-attachments/assets/869109db-ba7b-4704-bb86-1578013f944d)


- ğŸ“š Feedback History
- 
  ![image](https://github.com/user-attachments/assets/4a8f8eed-1cc9-4aba-a22d-c178c70abb9b)
  

- ğŸ“Š Visualization Reports
- 
  ![image](https://github.com/user-attachments/assets/27fc4232-1f3c-41a2-9dad-6c2aea849e0e)

- ğŸ“ˆ Analysis Page

  ![Uploading image.pngâ€¦]()


## âœ¨ Additional Features
- ğŸ›’ Category-wise Product Feedback
- ğŸ•’ Feedback History Tracking
- ğŸ“Š Dynamic Visualizations

## ğŸš€ Future Enhancements
- ğŸŒ Multilingual Support
- ğŸ”„ Automated Gradio Deployment
- ğŸ§‘â€ğŸ’¼ Role-Based Access Control
- ğŸ“± Mobile App Extension

âš¡ **Important Notes**
- Ensure MongoDB, Node.js backend, and Python backend are active before running the application.
- Always manually update the Gradio link inside `main.py` after starting Gradio.
